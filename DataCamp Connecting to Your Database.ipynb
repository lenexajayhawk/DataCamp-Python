{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course focuses on using the SQLAlchemy library.\n",
    "\n",
    "Engines and Connection Strings\n",
    "\n",
    "Alright, it's time to create your first engine! An engine is just a common interface to a database, and the information it requires to connect to one is contained in a connection string, such as sqlite:///census_nyc.sqlite. Here, sqlite is the database driver, while census_nyc.sqlite is a SQLite file contained in the local directory.\n",
    "\n",
    "You can learn a lot more about connection strings in the SQLAlchemy documentation.\n",
    "\n",
    "Your job in this exercise is to create an engine that connects to a local SQLite file named census.sqlite. Then, print the names of the tables it contains using the .table_names() method. Note that when you just want to print the table names, you do not need to use engine.connect() after creating the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine that connects to the census.sqlite file: engine\n",
    "engine = create_engine('sqlite:///census.sqlite')\n",
    "\n",
    "# Print table names\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoloading Tables from a Database\n",
    "\n",
    "SQLAlchemy can be used to automatically load tables from a database using something called reflection. Reflection is the process of reading the database and building the metadata based on that information. It's the opposite of creating a Table by hand and is very useful for working with existing databases. To perform reflection, you need to import the Table object from the SQLAlchemy package. Then, you use this Table object to read your table from the engine and autoload the columns. Using the Table object in this manner is a lot like passing arguments to a function. For example, to autoload the columns with the engine, you have to specify the keyword arguments autoload=True and autoload_with=engine to Table().\n",
    "\n",
    "In this exercise, your job is to reflect the census table available on your engine into a variable called census. The metadata has already been loaded for you using MetaData() and is available in the variable metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Table\n",
    "from sqlalchemy import Table\n",
    "\n",
    "# Reflect census table from the engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Print census table metadata\n",
    "# What does REPR mean and do?\n",
    "print(repr(census))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing Table Details\n",
    "\n",
    "Great job reflecting the census table! Now you can begin to learn more about the columns and structure of your table. It is important to get an understanding of your database by examining the column names. This can be done by using the .columns attribute and accessing the .keys() method. For example, census.columns.keys() would return a list of column names of the census table.\n",
    "\n",
    "Following this, we can use the metadata container to find out more details about the reflected table such as the columns and their types. For example, table objects are stored in the metadata.tables dictionary, so you can get the metadata of your census table with metadata.tables['census']. This is similar to your use of the repr() function on the census table from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflect the census table from the engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Print the column names\n",
    "print(census.columns.keys())\n",
    "\n",
    "# Print full table metadata\n",
    "print(repr(metadata.tables['census']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting data from a Table: raw SQL\n",
    "\n",
    "Using what we just learned about SQL and applying the .execute() method on our connection, we can leverage a raw SQL query to query all the records in our census table. The object returned by the .execute() method is a ResultProxy. On this ResultProxy, we can then use the .fetchall() method to get our results - that is, the ResultSet.\n",
    "\n",
    "In this exercise, you'll use a traditional SQL query. In the next exercise, you'll move to SQLAlchemy and begin to understand its advantages. Go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build select statement for census table: stmt\n",
    "stmt = 'SELECT * FROM census'\n",
    "\n",
    "# Execute the statement and fetch the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting data from a Table with SQLAlchemy\n",
    "\n",
    "Excellent work so far! It's now time to build your first select statement using SQLAlchemy. SQLAlchemy provides a nice \"Pythonic\" way of interacting with databases. So rather than dealing with the differences between specific dialects of traditional SQL such as MySQL or PostgreSQL, you can leverage the Pythonic framework of SQLAlchemy to streamline your workflow and more efficiently query your data. For this reason, it is worth learning even if you may already be familiar with traditional SQL.\n",
    "\n",
    "In this exercise, you'll once again build a statement to query all records from the census table. This time, however, you'll make use of the select() function of the sqlalchemy module. This function requires a list of tables or columns as the only required argument.\n",
    "\n",
    "Table and MetaData have already been imported. The metadata is available as metadata and the connection to the database as connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import select\n",
    "from sqlalchemy import select\n",
    "\n",
    "# Reflect census table via engine: census\n",
    "census = Table('census', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Build select statement for census table: stmt\n",
    "# Even a single attribute MUST be passed as a list\n",
    "stmt = select([census])\n",
    "\n",
    "# Print the emitted statement to see the SQL emitted\n",
    "# Prints the table.variables for the entire table\n",
    "print(stmt)\n",
    "\n",
    "# Execute the statement and print the results\n",
    "print(connection.execute(stmt).fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling a ResultSet\n",
    "\n",
    "Recall the differences between a ResultProxy and a ResultSet:\n",
    "\n",
    "ResultProxy: The object returned by the .execute() method. It can be used in a variety of ways to get the data returned by the query.\n",
    "\n",
    "ResultSet: The actual data asked for in the query when using a fetch method such as .fetchall() on a ResultProxy.\n",
    "This separation between the ResultSet and ResultProxy allows us to fetch as much or as little data as we desire.\n",
    "\n",
    "Once we have a ResultSet, we can use Python to access all the data within it by column name and by list style indexes. For example, you can get the first row of the results by using results[0]. With that first row then assigned to a variable first_row, you can get data from the first column by either using first_row[0] or by column name such as first_row['column_name']. You'll now practice exactly this using the ResultSet you obtained from the census table in the previous exercise. It is stored in the variable results. Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first row of the results by using an index: first_row\n",
    "first_row = results[0]\n",
    "\n",
    "# Print the first row of the results\n",
    "print(first_row)\n",
    "\n",
    "# Print the first column of the first row by using an index\n",
    "print(first_row[0])\n",
    "\n",
    "# Print the 'state' column of the first row by using its name\n",
    "print(first_row['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to a PostgreSQL Database\n",
    "\n",
    "In these exercises, you will be working with real databases hosted on the cloud via Amazon Web Services (AWS)!\n",
    "\n",
    "Let's begin by connecting to a PostgreSQL database. When connecting to a PostgreSQL database, many prefer to use the psycopg2 database driver as it supports practically all of PostgreSQL's features efficiently and is the standard dialect for PostgreSQL in SQLAlchemy.\n",
    "\n",
    "You might recall from Chapter 1 that we use the create_engine() function and a connection string to connect to a database.\n",
    "\n",
    "There are three components to the connection string in this exercise: the dialect and driver ('postgresql+psycopg2://'), followed by the username and password ('student:datacamp'), followed by the host and port ('@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/'), and finally, the database name ('census'). You will have to pass this string as an argument to create_engine() in order to connect to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine to the census database\n",
    "engine = create_engine('postgresql+psycopg2://student:datacamp@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/census')\n",
    "\n",
    "# Use the .table_names() method on the engine to print the table names\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data selected from a Table - Simple\n",
    "\n",
    "Having connected to the database, it's now time to practice filtering your queries!\n",
    "\n",
    "As mentioned in the video, a where() clause is used to filter the data that a statement returns. For example, to select all the records from the census table where the sex is Female (or 'F') we would do the following:\n",
    "\n",
    "select([census]).where(census.columns.sex == 'F')\n",
    "\n",
    "In addition to == we can use basically any python comparison operator (such as <=, !=, etc) in the where() clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a select query: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Add a where clause to filter the results to only those for New York\n",
    "stmt = stmt.where(census.columns.state == 'New York')\n",
    "\n",
    "# Execute the query to retrieve all the data returned: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Loop over the results and print the age, sex, and pop2008\n",
    "for result in results:\n",
    "    print(result.age, result.sex, result.pop2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data selected from a Table - Expressions\n",
    "\n",
    "In addition to standard Python comparators, we can also use methods such as in_() to create more powerful where() clauses. You can see a full list of expressions in the SQLAlchemy Documentation.\n",
    "\n",
    "We've already created a list of some of the most densely populated states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query for the census table: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Append a where clause to match all the states in_ the list states\n",
    "stmt = stmt.where(census.columns.state.in_(states))\n",
    "\n",
    "# Loop over the ResultProxy and print the state and its population in 2000\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.state, result.pop2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data selected from a Table - Advanced\n",
    "\n",
    "You're really getting the hang of this! SQLAlchemy also allows users to use conjunctions such as and_(), or_(), and not_() to build more complex filtering. For example, we can get a set of records for people in New York who are 21 or 37 years old with the following code:\n",
    "\n",
    "select([census]).where(\n",
    "  and_(census.columns.state == 'New York',\n",
    "       or_(census.columns.age == 21,\n",
    "          census.columns.age == 37\n",
    "         )\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and_\n",
    "from sqlalchemy import and_\n",
    "\n",
    "# Build a query for the census table: stmt\n",
    "stmt = select([census])\n",
    "\n",
    "# Append a where clause to select only non-male records from California using and_\n",
    "stmt = stmt.where(\n",
    "    # The state of California with a non-male sex\n",
    "    and_(census.columns.state == 'California',\n",
    "         census.columns.sex != 'M'\n",
    "         )\n",
    ")\n",
    "\n",
    "# Loop over the ResultProxy printing the age and sex\n",
    "for result in connection.execute(stmt):\n",
    "    print(result.age, result.sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordering by a Single Column\n",
    "\n",
    "To sort the result output by a field, we use the .order_by() method. By default, the .order_by() method sorts from lowest to highest on the supplied column. You just have to pass in the name of the column you want sorted to .order_by().\n",
    "\n",
    "In the video, for example, Jason used stmt.order_by(census.columns.state) to sort the result output by the state column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query to select the state column: stmt\n",
    "stmt = select([census.columns.state])\n",
    "\n",
    "# Order stmt by the state column\n",
    "stmt = stmt.order_by(census.columns.state)\n",
    "\n",
    "# Execute the query and store the results: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the first 10 results\n",
    "print(results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordering in Descending Order by a Single Column\n",
    "\n",
    "You can also use .order_by() to sort from highest to lowest by wrapping a column in the desc() function. Although you haven't seen this function in action, it generalizes what you have already learned.\n",
    "\n",
    "Pass desc() (for \"descending\") inside an .order_by() with the name of the column you want to sort by. For instance, stmt.order_by(desc(table.columns.column_name)) sorts column_name in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import desc\n",
    "from sqlalchemy import desc\n",
    "\n",
    "# Build a query to select the state column: stmt\n",
    "stmt = select([census.columns.state])\n",
    "\n",
    "# Order stmt by state in descending order: rev_stmt\n",
    "rev_stmt = stmt.order_by(desc(census.columns.state))\n",
    "\n",
    "# Execute the query and store the results: rev_results\n",
    "rev_results = connection.execute(rev_stmt).fetchall()\n",
    "\n",
    "# Print the first 10 rev_results\n",
    "print(rev_results[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordering by Multiple Columns\n",
    "\n",
    "We can pass multiple arguments to the .order_by() method to order by multiple columns. In fact, we can also sort in ascending or descending order for each individual column. Each column in the .order_by() method is fully sorted from left to right. This means that the first column is completely sorted, and then within each matching group of values in the first column, it's sorted by the next column in the .order_by() method. This process is repeated until all the columns in the .order_by() are sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query to select state and age: stmt\n",
    "stmt = select([census.columns.state, census.columns.age])\n",
    "\n",
    "# Append order by to ascend by state and descend by age\n",
    "stmt = stmt.order_by(census.columns.state, desc(census.columns.age))\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the first 20 results\n",
    "print(results[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Distinct Data\n",
    "\n",
    "As mentioned in the video, SQLAlchemy's func module provides access to built-in SQL functions that can make operations like counting and summing faster and more efficient.\n",
    "\n",
    "In the video, Jason used func.sum() to get a sum of the pop2008 column of census as shown below:\n",
    "\n",
    "select([func.sum(census.columns.pop2008)])\n",
    "\n",
    "If instead you want to count the number of values in pop2008, you could use func.count() like this:\n",
    "\n",
    "select([func.count(census.columns.pop2008)])\n",
    "\n",
    "Furthermore, if you only want to count the distinct values of pop2008, you can use the .distinct() method:\n",
    "\n",
    "select([func.count(census.columns.pop2008.distinct())])\n",
    "\n",
    "In this exercise, you will practice using func.count() and .distinct() to get a count of the distinct number of states in census.\n",
    "\n",
    "So far, you've seen .fetchall() and .first() used on a ResultProxy to get the results. The ResultProxy also has a method called .scalar() for getting just the value of a query that returns only one row and column.\n",
    "\n",
    "This can be very useful when you are querying for just a count or sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a query to count the distinct states values: stmt\n",
    "stmt = select([func.count(census.columns.state.distinct())])\n",
    "\n",
    "# Execute the query and store the scalar result: distinct_state_count\n",
    "distinct_state_count = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the distinct_state_count\n",
    "print(distinct_state_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of Records by State\n",
    "\n",
    "Often, we want to get a count for each record with a particular value in another column. The .group_by() method helps answer this type of query. You can pass a column to the .group_by() method and use in an aggregate function like sum() or count(). Much like the .order_by() method, .group_by() can take multiple columns as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import func\n",
    "from sqlalchemy import func\n",
    "\n",
    "# Build a query to select the state and count of ages by state: stmt\n",
    "stmt = select([census.columns.state, func.count(census.columns.age)])\n",
    "\n",
    "# Group stmt by state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print results\n",
    "print(results)\n",
    "\n",
    "# Print the keys/column names of the results returned\n",
    "print(results[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the Population Sum by State\n",
    "\n",
    "To avoid confusion with query result column names like count_1, we can use the .label() method to provide a name for the resulting column. This gets appendedto the function method we are using, and its argument is the name we want to use.\n",
    "\n",
    "We can pair func.sum() with .group_by() to get a sum of the population by State and use the label() method to name the output.\n",
    "\n",
    "We can also create the func.sum() expression before using it in the select statement. We do it the same way we would inside the select statement and store it in a variable. Then we use that variable in the select statement where the func.sum() would normally be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import func\n",
    "from sqlalchemy import func\n",
    "\n",
    "# Build an expression to calculate the sum of pop2008 labeled as population\n",
    "pop2008_sum = func.sum(census.columns.pop2008).label('population')\n",
    "\n",
    "# Build a query to select the state and sum of pop2008: stmt\n",
    "stmt = select([census.columns.state, pop2008_sum])\n",
    "\n",
    "# Group stmt by state\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Execute the statement and store all the records: results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print results\n",
    "print(results)\n",
    "\n",
    "# Print the keys/column names of the results returned\n",
    "print(results[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLAlchemy ResultsProxy and Pandas Dataframes\n",
    "\n",
    "We can feed a ResultProxy directly into a pandas DataFrame, which is the workhorse of many Data Scientists in PythonLand. Jason demonstrated this in the video. In this exercise, you'll follow exactly the same approach to convert a ResultProxy into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from the results: df\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set column names\n",
    "df.columns = results[0].keys()\n",
    "\n",
    "# Print the Dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From SQLAlchemy results to a Graph\n",
    "\n",
    "We can also take advantage of pandas and Matplotlib to build figures of our data. Remember that data visualization is essential for both exploratory data analysis and communication of your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyplot as plt from matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame from the results: df\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Set Column names\n",
    "df.columns = results[0].keys()\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Plot the DataFrame\n",
    "df.plot.bar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to a MySQL Database\n",
    "\n",
    "Before you jump into the calculation exercises, let's begin by connecting to our database. Recall that in the last chapter you connected to a PostgreSQL database. Now, you'll connect to a MySQL database, for which many prefer to use the pymysql database driver, which, like psycopg2 for PostgreSQL, you have to install prior to use.\n",
    "\n",
    "This connection string is going to start with 'mysql+pymysql://', indicating which dialect and driver you're using to establish the connection. The dialect block is followed by the 'username:password' combo. Next, you specify the host and port with the following '@host:port/'. Finally, you wrap up the connection string with the 'database_name'.\n",
    "\n",
    "Now you'll practice connecting to a MySQL database: it will be the same census database that you have already been working with. One of the great things about SQLAlchemy is that, after connecting, it abstracts over the type of database it has connected to and you can write the same SQLAlchemy code, regardless!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import create_engine function\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create an engine to the census database\n",
    "engine = create_engine('mysql+pymysql://student:datacamp@courses.csrrinzqubik.us-east-1.rds.amazonaws.com:3306/census')\n",
    "\n",
    "# Print the table names\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating a Difference between Two Columns\n",
    "\n",
    "Often, you'll need to perform math operations as part of a query, such as if you wanted to calculate the change in population from 2000 to 2008. For math operations on numbers, the operators in SQLAlchemy work the same way as they do in Python.\n",
    "\n",
    "You can use these operators to perform addition (+), subtraction (-), multiplication (*), division (/), and modulus (%) operations. Note: They behave differently when used with non-numeric column types.\n",
    "\n",
    "Let's now find the top 5 states by population growth between 2000 and 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build query to return state names by population difference from 2008 to 2000: stmt\n",
    "stmt = select([census.columns.state, (census.columns.pop2008-census.columns.pop2000).label('pop_change')])\n",
    "\n",
    "# Append group by for the state: stmt\n",
    "stmt = stmt.group_by(census.columns.state)\n",
    "\n",
    "# Append order by for pop_change descendingly: stmt\n",
    "stmt = stmt.order_by(desc('pop_change'))\n",
    "\n",
    "# Return only 5 results: stmt\n",
    "stmt = stmt.limit(5)\n",
    "\n",
    "# Use connection to execute the statement and fetch all results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Print the state and population change for each record\n",
    "for result in results:\n",
    "    print('{}:{}'.format(result.state, result.pop_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the Overall Percentage of Females\n",
    "\n",
    "It's possible to combine functions and operators in a single select statement as well. These combinations can be exceptionally handy when we want to calculate percentages or averages, and we can also use the case() expression to operate on data that meets specific criteria while not affecting the query as a whole. The case() expression accepts a list of conditions to match and the column to return if the condition matches, followed by an else_ if none of the conditions match. We can wrap this entire expression in any function or math operation we like.\n",
    "\n",
    "Often when performing integer division, we want to get a float back. While some databases will do this automatically, you can use the cast() function to convert an expression to a particular type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import case, cast and Float from sqlalchemy\n",
    "from sqlalchemy import case, cast, Float\n",
    "\n",
    "# Build an expression to calculate female population in 2000\n",
    "female_pop2000 = func.sum(\n",
    "    case([\n",
    "        (census.columns.sex == 'F', census.columns.pop2000)\n",
    "    ], else_=0))\n",
    "\n",
    "# Cast an expression to calculate total population in 2000 to Float\n",
    "total_pop2000 = cast(func.sum(census.columns.pop2000), Float)\n",
    "\n",
    "# Build a query to calculate the percentage of females in 2000: stmt\n",
    "stmt = select([female_pop2000 / total_pop2000 * 100])\n",
    "\n",
    "# Execute the query and store the scalar result: percent_female\n",
    "percent_female = connection.execute(stmt).scalar()\n",
    "\n",
    "# Print the percentage\n",
    "print(percent_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic Joins with an Established Relationship\n",
    "\n",
    "If you have two tables that already have an established relationship, you can automatically use that relationship by just adding the columns we want from each table to the select statement. Recall that Jason constructed the following query:\n",
    "\n",
    "stmt = select([census.columns.pop2008, state_fact.columns.abbreviation])\n",
    "\n",
    "in order to join the census and state_fact tables and select the pop2008 column from the first and the abbreviation column from the second. In this case, the census and state_fact tables had a pre-defined relationship: the state column of the former corresponded to the name column of the latter.\n",
    "\n",
    "In this exercise, you'll use the same predefined relationship to select the pop2000 and abbreviation columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to join census and state_fact tables: stmt\n",
    "stmt = select([census.columns.pop2000, state_fact.columns.abbreviation])\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joins\n",
    "\n",
    "If you aren't selecting columns from both tables or the two tables don't have a defined relationship, you can still use the .join() method on a table to join it with another table and get extra data related to our query. The join() takes the table object you want to join in as the first argument and a condition that indicates how the tables are related to the second argument. Finally, you use the .select_from() method on the select statement to wrap the join clause. For example, in the video, Jason executed the following code to join the census table to the state_fact table such that the state column of the census table corresponded to the name column of the state_fact table.\n",
    "\n",
    "stmt = stmt.select_from(\n",
    "    census.join(\n",
    "        state_fact, census.columns.state == \n",
    "        state_fact.columns.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a statement to select the census and state_fact tables: stmt\n",
    "stmt = select([census, state_fact])\n",
    "\n",
    "# Add a select_from clause that wraps a join for the census and state_fact\n",
    "# tables where the census state column and state_fact name column match\n",
    "stmt = stmt.select_from(\n",
    "    census.join(state_fact, census.columns.state == state_fact.columns.name))\n",
    "\n",
    "# Execute the statement and get the first result: result\n",
    "result = connection.execute(stmt).first()\n",
    "\n",
    "# Loop over the keys in the result object and print the key and value\n",
    "for key in result.keys():\n",
    "    print(key, getattr(result, key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
