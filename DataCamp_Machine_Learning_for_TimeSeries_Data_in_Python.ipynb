{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a time series (I)\n",
    "\n",
    "In this exercise, you'll practice plotting the values of two time series without the time component.\n",
    "\n",
    "Two DataFrames, data and data2 are available in your workspace.\n",
    "\n",
    "Unless otherwise noted, assume that all required packages are loaded with their common aliases throughout this course.\n",
    "\n",
    "Note: This course assumes some familiarity with time series data, as well as how to use them in data analytics pipelines. For an introduction to time series, we recommend the Introduction to Time Series Analysis in Python and Visualizing Time Series Data with Python courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series in each dataset\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
    "data.iloc[:1000].plot(y='data_values', ax=axs[0])\n",
    "data2.iloc[:1000].plot(y='data_values', ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a time series (II)\n",
    "\n",
    "You'll now plot both the datasets again, but with the included time stamps for each (stored in the column called \"time\"). Let's see if this gives you some more context for understanding each time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series in each dataset\n",
    "fig, axs = plt.subplots(2, 1, figsize=(5, 10))\n",
    "data.iloc[:1000].plot(x='time', y='data_values', ax=axs[0])\n",
    "data2.iloc[:1000].plot(x='time', y='data_values', ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a simple model: classification\n",
    "\n",
    "In this exercise, you'll use the iris dataset (representing petal characteristics of a number of flowers) to practice using the scikit-learn API to fit a classification model. You can see a sample plot of the data to the right.\n",
    "\n",
    "Note: This course assumes some familiarity with Machine Learning and scikit-learn. For an introduction to scikit-learn, we recommend the Supervised Learning with Scikit-Learn and Preprocessing for Machine Learning in Python courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Construct data for the model\n",
    "X = data[['petal length (cm)', 'petal width (cm)']]\n",
    "y = data[['target']]\n",
    "\n",
    "# Fit the model\n",
    "model = LinearSVC()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting using a classification model\n",
    "\n",
    "Now that you have fit your classifier, let's use it to predict the type of flower (or class) for some newly-collected flowers.\n",
    "\n",
    "Information about petal width and length for several new flowers is stored in the variable targets. Using the classifier you fit, you'll predict the type of each flower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input array\n",
    "X_predict = targets[['petal length (cm)', 'petal width (cm)']]\n",
    "\n",
    "# Predict with the model\n",
    "predictions = model.predict(X_predict)\n",
    "print(predictions)\n",
    "\n",
    "# Visualize predictions and actual values\n",
    "plt.scatter(X_predict['petal length (cm)'], X_predict['petal width (cm)'],\n",
    "            c=predictions, cmap=plt.cm.coolwarm)\n",
    "plt.title(\"Predicted class values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a simple model: regression\n",
    "\n",
    "In this exercise, you'll practice fitting a regression model using data from the Boston housing market. A DataFrame called boston is available in your workspace. It contains many variables of data (stored as columns). Can you find a relationship between the following two variables?\n",
    "\n",
    "\"AGE\": proportion of owner-occupied units built prior to 1940\n",
    "\"RM\" : average number of rooms per dwelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Prepare input and output DataFrames\n",
    "X = boston.AGE.reshape(-1, 1)\n",
    "y = boston.RM.reshape(-1, 1)\n",
    "\n",
    "# Fit the model\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting using a regression model\n",
    "\n",
    "Now that you've fit a model with the Boston housing data, lets see what predictions it generates on some new data. You can investigate the underlying relationship that the model has found between inputs and outputs by feeding in a range of numbers as inputs and seeing what the model predicts for each input.\n",
    "\n",
    "A 1-D array new_inputs consisting of 100 \"new\" values for \"AGE\" (proportion of owner-occupied units built prior to 1940) is available in your workspace along with the model you fit in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions with the model using those inputs\n",
    "predictions = model.predict(new_inputs.reshape(-1, 1))\n",
    "\n",
    "# Visualize the inputs and predicted values\n",
    "plt.scatter(new_inputs, predictions, color='r', s=3)\n",
    "plt.xlabel('inputs')\n",
    "plt.ylabel('predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the classification data\n",
    "\n",
    "In these final exercises of this chapter, you'll explore the two datasets you'll use in this course.\n",
    "\n",
    "The first is a collection of heartbeat sounds. Hearts normally have a predictable sound pattern as they beat, but some disorders can cause the heart to beat abnormally. This dataset contains a training set with labels for each type of heartbeat, and a testing set with no labels. You'll use the testing set to validate your models.\n",
    "\n",
    "As you have labeled data, this dataset is ideal for classification. In fact, it was originally offered as a part of a public Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "from glob import glob\n",
    "\n",
    "# List all the wav files in the folder\n",
    "audio_files = glob(data_dir + '/*.wav')\n",
    "\n",
    "# Read in the first audio file, create the time array\n",
    "audio, sfreq = lr.load(audio_files[0])\n",
    "time = np.arange(0, len(audio)) / sfreq\n",
    "\n",
    "# Plot audio over time\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(time, audio)\n",
    "ax.set(xlabel='Time (s)', ylabel='Sound Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the regression data\n",
    "\n",
    "The next dataset contains information about company market value over several years of time. This is one of the most popular kind of time series data used for regression. If you can model the value of a company as it changes over time, you can make predictions about where that company will be in the future. This dataset was also originally provided as part of a public Kaggle competition.\n",
    "\n",
    "In this exercise, you'll plot the time series for a number of companies to get an understanding of how they are (or aren't) related to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "data = pd.read_csv('prices.csv', index_col=0)\n",
    "\n",
    "# Convert the index of the DataFrame to datetime\n",
    "data.index = pd.to_datetime(data.index)\n",
    "print(data.head())\n",
    "\n",
    "# Loop through each column, plot its values over time\n",
    "fig, ax = plt.subplots()\n",
    "for column in data:\n",
    "    data[column].plot(ax=ax, label=column)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many repetitions of sounds\n",
    "\n",
    "In this exercise, you'll start with perhaps the simplest classification technique: averaging across dimensions of a dataset and visually inspecting the result.\n",
    "\n",
    "You'll use the heartbeat data described in the last chapter. Some recordings are normal heartbeat activity, while others are abnormal activity. Let's see if you can spot the difference.\n",
    "\n",
    "Two DataFrames, normal and abnormal, each with the shape of (n_times_points, n_audio_files) containing the audio for several heartbeats are available in your workspace. Also, the sampling frequency is loaded into a variable called sfreq. A convenience plotting function show_plot_and_make_titles() is also available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(15, 7), sharex=True, sharey=True)\n",
    "\n",
    "# Calculate the time array\n",
    "time = np.arange(0, len(normal)) / sfreq\n",
    "\n",
    "# Stack the normal/abnormal audio so you can loop and plot\n",
    "stacked_audio = np.hstack([normal, abnormal]).T\n",
    "\n",
    "# Loop through each audio file / ax object and plot\n",
    "# .T.ravel() transposes the array, then unravels it into a 1-D vector for looping\n",
    "for iaudio, ax in zip(stacked_audio, axs.T.ravel()):\n",
    "    ax.plot(time, iaudio)\n",
    "show_plot_and_make_titles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invariance in time\n",
    "\n",
    "While you should always start by visualizing your raw data, this is often uninformative when it comes to discriminating between two classes of data points. Data is usually noisy or exhibits complex patterns that aren't discoverable by the naked eye.\n",
    "\n",
    "Another common technique to find simple differences between two sets of data is to average across multiple instances of the same class. This may remove noise and reveal underlying patterns (or, it may not).\n",
    "\n",
    "In this exercise, you'll average across many instances of each class of heartbeat sound.\n",
    "\n",
    "The two DataFrames (normal and abnormal) and the time array (time) from the previous exercise are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average across the audio files of each DataFrame\n",
    "mean_normal = np.mean(normal, axis=1)\n",
    "mean_abnormal = np.mean(abnormal, axis=1)\n",
    "\n",
    "# Plot each average over time\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
    "ax1.plot(time, mean_normal)\n",
    "ax1.set(title=\"Normal Data\")\n",
    "ax2.plot(time, mean_abnormal)\n",
    "ax2.set(title=\"Abnormal Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a classification model\n",
    "\n",
    "While eye-balling differences is a useful way to gain an intuition for the data, let's see if you can operationalize things with a model. In this exercise, you will use each repetition as a datapoint, and each moment in time as a feature to fit a classifier that attempts to predict abnormal vs. normal heartbeats using only the raw data.\n",
    "\n",
    "We've split the two DataFrames (normal and abnormal) into X_train, X_test, y_train, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
